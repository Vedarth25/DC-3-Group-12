{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with images \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT!- Change local path to images wherever there is \"image=...\" in the code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main questions: Which of the methods (brightness, contrast, color correction, saturation, hue, exposure), etc is best to use? Should we use a combination? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell first to import cv2 and to check if your image loads correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not load image. Check the file path.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Escape each backslash with another backslash\n",
    "image = cv2.imread('C:\\\\Users\\\\User\\\\OneDrive\\\\Documents\\\\Data Challenge 3\\\\DC-3-Group-12\\\\Preprocessing\\\\9870_Gerres_f000170.jpg')\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Check the file path.\")\n",
    "else:\n",
    "    cv2.imshow('Image', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Display the image\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Specify the path to your image\n",
    "image_path = r'C:\\Users\\User\\OneDrive\\Documents\\Data Challenge 3\\DC-3-Group-12\\Preprocessing\\9908_Epinephelus_f000127.jpg'\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code just adds contrast and brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.5  # Contrast control (1.0-3.0), >1 increases contrast, <1 decreases contrast\n",
    "beta = 0   # Brightness control (0-100), >0 increases brightness, <0 decreases brightness\n",
    "\n",
    "# Apply the adjustments to the image\n",
    "adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "# Display the original and adjusted images side by side\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Adjusted Brightness and Contrast Image', adjusted_image)\n",
    "\n",
    "# Wait for a key press and close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code first checks the brightness and the contrast of the image and enhances them as needed based on a certain threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Brightness: 145.08\n",
      "Initial Contrast: 40.04\n",
      "Adjusted Brightness: 193.00\n",
      "Adjusted Contrast: 49.74\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_brightness_contrast(image):\n",
    "    # Convert image to grayscale for brightness calculation\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the mean brightness\n",
    "    brightness = np.mean(gray)\n",
    "\n",
    "    # Calculate contrast as the standard deviation of pixel values\n",
    "    contrast = np.std(gray)\n",
    "\n",
    "    return brightness, contrast\n",
    "\n",
    "def adjust_brightness_contrast(image, target_brightness=128, target_contrast=64):\n",
    "    brightness, contrast = calculate_brightness_contrast(image)\n",
    "    \n",
    "    # Calculate the adjustment factors, but constrain them to avoid extreme adjustments\n",
    "    alpha = min(max(target_contrast / max(contrast, 1e-6), 0.5), 1.5)  # Adjust contrast, constrained between 0.5 and 1.5\n",
    "    beta = min(max(target_brightness - brightness, -100), 100)  # Adjust brightness, constrained between -100 and 100\n",
    "    \n",
    "    # Apply the adjustments\n",
    "    adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return adjusted_image\n",
    "     \n",
    "# Load the image\n",
    "image_path = r'C:\\Users\\User\\OneDrive\\Documents\\Data Challenge 3\\DC-3-Group-12\\Preprocessing\\7393_F1_f000513.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Check the file path.\")\n",
    "else:\n",
    "    # Calculate initial brightness and contrast\n",
    "    initial_brightness, initial_contrast = calculate_brightness_contrast(image)\n",
    "    print(f\"Initial Brightness: {initial_brightness:.2f}\")\n",
    "    print(f\"Initial Contrast: {initial_contrast:.2f}\")\n",
    "\n",
    "    # Adjust brightness and contrast based on initial values\n",
    "    adjusted_image = adjust_brightness_contrast(image)\n",
    "\n",
    "    # Calculate adjusted brightness and contrast\n",
    "    adjusted_brightness, adjusted_contrast = calculate_brightness_contrast(adjusted_image)\n",
    "    print(f\"Adjusted Brightness: {adjusted_brightness:.2f}\")\n",
    "    print(f\"Adjusted Contrast: {adjusted_contrast:.2f}\")\n",
    "\n",
    "    # Display the original and adjusted images\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Adjusted Image', adjusted_image)\n",
    "\n",
    "    # Wait for a key press and close the windows\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is a combination of methods: adjust brightness, contrast, does Color Correction with \n",
    "White Balance Adjustment: Underwater images often have a blue or green tint. Correcting white balance helps to restore natural colors.\n",
    "Histogram Equalization: Equalize the histogram of each color channel (R, G, B) to balance color distribution. Also it applie Bilateral Filter: Smoothens the image while preserving edges, which is useful for reducing noise. It also adds . CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "CLAHE enhances contrast in local regions of the image, improving details without over-amplifying noise. However using them all together is probably too much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_brightness_contrast(image):\n",
    "    # Convert image to grayscale for brightness calculation\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the mean brightness and contrast\n",
    "    brightness = np.mean(gray)\n",
    "    contrast = np.std(gray)\n",
    "    return brightness, contrast\n",
    "\n",
    "def adjust_brightness_contrast(image, alpha=1.5, beta=30):\n",
    "    # Adjust brightness and contrast\n",
    "    return cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "def correct_white_balance(image):\n",
    "    # Convert to LAB color space and apply CLAHE\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l = clahe.apply(l)\n",
    "    corrected_image = cv2.merge((l, a, b))\n",
    "    return cv2.cvtColor(corrected_image, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def apply_bilateral_filter(image):\n",
    "    # Apply bilateral filter for smoothing\n",
    "    return cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "def apply_clahe(image):\n",
    "    # Apply CLAHE to enhance local contrast\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    enhanced_image = cv2.merge((l_clahe, a, b))\n",
    "    return cv2.cvtColor(enhanced_image, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# Load the underwater image\n",
    "image_path = r'C:\\Users\\User\\OneDrive\\Documents\\Data Challenge 3\\DC-3-Group-12\\Preprocessing\\7393_F1_f000513.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Check the file path.\")\n",
    "else:\n",
    "    # Adjust brightness and contrast\n",
    "    adjusted_image = adjust_brightness_contrast(image)\n",
    "\n",
    "    # Apply white balance correction\n",
    "    wb_corrected_image = correct_white_balance(adjusted_image)\n",
    "\n",
    "    # Apply CLAHE\n",
    "    clahe_image = apply_clahe(wb_corrected_image)\n",
    "\n",
    "    # Apply bilateral filter\n",
    "    final_image = apply_bilateral_filter(clahe_image)\n",
    "\n",
    "    # Display the original and enhanced images\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Enhanced Image', final_image)\n",
    "\n",
    "    # Wait for a key press and close the windows\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code enhances saturation. Saturation modifies the color intensity. Larger values apply greater variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def enhance_saturation(image, saturation_scale=1.5):\n",
    "    # Convert the image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Split the channels\n",
    "    h, s, v = cv2.split(hsv_image)\n",
    "    \n",
    "    # Scale the saturation channel\n",
    "    s = s.astype(np.float32)  # Convert to float to prevent overflow\n",
    "    s *= saturation_scale\n",
    "    \n",
    "    # Clip the values to ensure they stay within [0, 255] and convert back to uint8\n",
    "    s = np.clip(s, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Merge the channels back\n",
    "    enhanced_hsv = cv2.merge([h, s, v])\n",
    "    \n",
    "    # Convert back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(enhanced_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return enhanced_image\n",
    "\n",
    "# Load the image\n",
    "image_path = r'C:\\Users\\User\\OneDrive\\Documents\\Data Challenge 3\\DC-3-Group-12\\Preprocessing\\7393_F1_f000513.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Check the file path.\")\n",
    "else:\n",
    "    # Enhance the saturation of the image\n",
    "    enhanced_image = enhance_saturation(image, saturation_scale=1.5)\n",
    "\n",
    "    # Display the original and enhanced images\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Enhanced Saturation Image', enhanced_image)\n",
    "\n",
    "    # Wait for a key press and close the windows\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code enhances exposure. (Exposure is kinda like a combination of brightness and contrast). Exposure determines the amount of black or white that is added to colors. The higher the value, the greater the variance, possibly making it appear as if the images were over-or under-exposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def enhance_exposure(image, exposure_factor=1.2):\n",
    "    # Convert the image to the LAB color space\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Split the LAB image into separate channels\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "    \n",
    "    # Convert the L channel to float to avoid overflow\n",
    "    l = l.astype(np.float32)\n",
    "    \n",
    "    # Enhance exposure by scaling the L channel\n",
    "    l *= exposure_factor\n",
    "    \n",
    "    # Clip the values to [0, 255] and convert back to uint8\n",
    "    l = np.clip(l, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Merge the channels back\n",
    "    enhanced_lab = cv2.merge((l, a, b))\n",
    "    \n",
    "    # Convert back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    return enhanced_image\n",
    "\n",
    "# Load the image\n",
    "image_path = r'C:\\Users\\User\\OneDrive\\Documents\\Data Challenge 3\\DC-3-Group-12\\Preprocessing\\7393_F1_f000513.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Check the file path.\")\n",
    "else:\n",
    "    # Enhance the exposure of the image\n",
    "    enhanced_image = enhance_exposure(image, exposure_factor=1.2)\n",
    "\n",
    "    # Display the original and enhanced images\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Enhanced Exposure Image', enhanced_image)\n",
    "\n",
    "    # Wait for a key press and close the windows\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code changes hue. Hue can be thought of as the “shade” of the colors in an image. The Hue augmentation changes the color channels of an input image at random, causing a model to explore several color schemes for objects and scenes in the image. This strategy is important for ensuring that a model does not memorize the colors of a given object or scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def enhance_hue(image, hue_shift=30):\n",
    "    # Convert the image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Split the channels\n",
    "    h, s, v = cv2.split(hsv_image)\n",
    "    \n",
    "    # Enhance the hue by adding the shift value\n",
    "    h = h.astype(np.int32)  # Convert to int32 to avoid overflow\n",
    "    h = (h + hue_shift) % 180  # Shift hue and wrap around using modulo operation\n",
    "    h = h.astype(np.uint8)  # Convert back to uint8\n",
    "    \n",
    "    # Merge the channels back\n",
    "    enhanced_hsv = cv2.merge([h, s, v])\n",
    "    \n",
    "    # Convert back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(enhanced_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return enhanced_image\n",
    "\n",
    "# Load the image\n",
    "image_path = r'C:\\Users\\User\\OneDrive\\Documents\\Data Challenge 3\\DC-3-Group-12\\Preprocessing\\7393_F1_f000513.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Check the file path.\")\n",
    "else:\n",
    "    # Enhance the hue of the image\n",
    "    enhanced_image = enhance_hue(image, hue_shift=30)\n",
    "\n",
    "    # Display the original and enhanced images\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Enhanced Hue Image', enhanced_image)\n",
    "\n",
    "    # Wait for a key press and close the windows\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opencv-python) (1.23.5)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/38.8 MB 5.1 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.6/38.8 MB 6.2 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.9/38.8 MB 6.1 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.6/38.8 MB 8.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.1/38.8 MB 9.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.6/38.8 MB 8.9 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.1/38.8 MB 9.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 3.6/38.8 MB 9.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.2/38.8 MB 10.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.9/38.8 MB 10.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.5/38.8 MB 10.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.2/38.8 MB 10.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.6/38.8 MB 10.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 7.0/38.8 MB 10.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.7/38.8 MB 10.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 8.0/38.8 MB 10.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 8.4/38.8 MB 10.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.0/38.8 MB 10.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.7/38.8 MB 10.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 10.0/38.8 MB 10.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 10.5/38.8 MB 11.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.2/38.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.5/38.8 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 11.8/38.8 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.1/38.8 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.6/38.8 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.1/38.8 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.6/38.8 MB 10.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 13.9/38.8 MB 10.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.5/38.8 MB 10.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.0/38.8 MB 10.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.2/38.8 MB 10.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 15.8/38.8 MB 10.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.3/38.8 MB 9.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 16.8/38.8 MB 9.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.3/38.8 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 17.8/38.8 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.3/38.8 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.5/38.8 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.7/38.8 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 19.1/38.8 MB 9.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.7/38.8 MB 9.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.1/38.8 MB 9.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 20.5/38.8 MB 9.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.0/38.8 MB 9.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.4/38.8 MB 9.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.9/38.8 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.5/38.8 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.9/38.8 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.3/38.8 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.8/38.8 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.3/38.8 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.5/38.8 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.2/38.8 MB 9.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.8/38.8 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.1/38.8 MB 9.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.5/38.8 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.7/38.8 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.2/38.8 MB 9.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.8/38.8 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.2/38.8 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.7/38.8 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.3/38.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 30.0/38.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.6/38.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 31.1/38.8 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.6/38.8 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.2/38.8 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.5/38.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.1/38.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.5/38.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.1/38.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.5/38.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.0/38.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.3/38.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.8/38.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.4/38.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.9/38.8 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.3/38.8 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.8/38.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.2/38.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 10.2 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These dont do anything "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def adjust_brightness_contrast(image, alpha=1.2, beta=10):\n",
    "    # Adjust brightness and contrast with clipping\n",
    "    adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return adjusted_image\n",
    "\n",
    "def apply_clahe(image):\n",
    "    # Convert image to LAB color space\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "\n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "\n",
    "    # Merge the CLAHE-enhanced L channel back with A and B channels\n",
    "    enhanced_image = cv2.merge((l_clahe, a, b))\n",
    "    return cv2.cvtColor(enhanced_image, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def apply_denoising(image):\n",
    "    # Apply fast NlMeansDenoisingColored\n",
    "    denoised_image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
    "    return denoised_image\n",
    "\n",
    "def selective_contrast(image):\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Selectively increase contrast in darker areas\n",
    "    l_mask = l < 120  # Mask for darker areas\n",
    "    l = np.where(l_mask, l * 1.2, l)  # Increase contrast in masked areas\n",
    "    lab_adjusted = cv2.merge([l, a, b])\n",
    "\n",
    "    # Convert back to BGR color space\n",
    "    result = cv2.cvtColor(lab_adjusted, cv2.COLOR_LAB2BGR)\n",
    "    return result\n",
    "\n",
    "# Load the uploaded image\n",
    "image_path = r'C:\\Users\\User\\OneDrive\\Documents\\Data Challenge 3\\DC-3-Group-12\\Preprocessing\\7393_F1_f000513.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Check the file path.\")\n",
    "else:\n",
    "    # Step 1: Apply CLAHE for better contrast\n",
    "    clahe_image = apply_clahe(image)\n",
    "\n",
    "    # Step 2: Selective contrast enhancement\n",
    "    selective_image = selective_contrast(clahe_image)\n",
    "\n",
    "    # Step 3: Apply slight brightness/contrast adjustment\n",
    "    adjusted_image = adjust_brightness_contrast(selective_image, alpha=1.1, beta=20)\n",
    "\n",
    "    # Step 4: Apply denoising to smooth the image\n",
    "    final_image = apply_denoising(adjusted_image)\n",
    "\n",
    "    # Display the original and enhanced images side by side\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Enhanced Image', final_image)\n",
    "\n",
    "    # Wait for a key press and close the windows\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def adjust_brightness_contrast(image, alpha=1.2, beta=10):\n",
    "    # Adjust brightness and contrast with clipping\n",
    "    adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return adjusted_image\n",
    "\n",
    "def apply_clahe(image):\n",
    "    # Convert image to LAB color space\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "\n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "\n",
    "    # Merge the CLAHE-enhanced L channel back with A and B channels\n",
    "    enhanced_image = cv2.merge((l_clahe, a, b))\n",
    "    return cv2.cvtColor(enhanced_image, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def apply_denoising(image):\n",
    "    # Apply fast NlMeansDenoisingColored\n",
    "    denoised_image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
    "    return denoised_image\n",
    "\n",
    "def selective_contrast(image):\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Ensure l is of type float32 for proper processing\n",
    "    l = l.astype(np.float32)\n",
    "\n",
    "    # Selectively increase contrast in darker areas\n",
    "    l_mask = l < 120  # Mask for darker areas\n",
    "    l = np.where(l_mask, l * 1.2, l)  # Increase contrast in masked areas\n",
    "\n",
    "    # Clip values to ensure they stay within the 0-255 range\n",
    "    l = np.clip(l, 0, 255).astype(np.uint8)  # Convert back to uint8 for merging\n",
    "\n",
    "    # Merge the channels back\n",
    "    lab_adjusted = cv2.merge([l, a, b])\n",
    "\n",
    "    # Convert back to BGR color space\n",
    "    result = cv2.cvtColor(lab_adjusted, cv2.COLOR_LAB2BGR)\n",
    "    return result\n",
    "\n",
    "# Load the uploaded image\n",
    "image_path = r'C:\\Users\\User\\OneDrive\\Documents\\Data Challenge 3\\DC-3-Group-12\\Preprocessing\\7393_F1_f000513.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Check the file path.\")\n",
    "else:\n",
    "    # Step 1: Apply CLAHE for better contrast\n",
    "    clahe_image = apply_clahe(image)\n",
    "\n",
    "    # Step 2: Selective contrast enhancement\n",
    "    selective_image = selective_contrast(clahe_image)\n",
    "\n",
    "    # Step 3: Apply slight brightness/contrast adjustment\n",
    "    adjusted_image = adjust_brightness_contrast(selective_image, alpha=1.1, beta=20)\n",
    "\n",
    "    # Step 4: Apply denoising to smooth the image\n",
    "    final_image = apply_denoising(adjusted_image)\n",
    "\n",
    "    # Display the original and enhanced images side by side\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Enhanced Image', final_image)\n",
    "\n",
    "    # Wait for a key press and close the windows\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
